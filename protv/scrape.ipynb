{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d32d369",
   "metadata": {},
   "source": [
    "# Scrape the ProTV news archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47211187",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from datetime import date, datetime\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def parse_date(date_str: str) -> date:\n",
    "    return datetime.strptime(date_str, '%d.%m.%Y').date()\n",
    "\n",
    "\n",
    "since = parse_date('05.06.2015')\n",
    "\n",
    "page = 1\n",
    "stop = False\n",
    "\n",
    "results = []\n",
    "\n",
    "while not stop:\n",
    "    html = requests.get(\n",
    "        f'https://stirileprotv.ro/video/stirile-diminetii/?page={page}'\n",
    "    ).text\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    for item in soup.select('div.vid_item'):\n",
    "        a_tag = item.find('a', href=True)\n",
    "        title_el = a_tag.find(class_='title')  # type: ignore\n",
    "\n",
    "        href = a_tag['href']  # type: ignore\n",
    "        title_text = title_el.get_text(strip=True)  # type: ignore\n",
    "\n",
    "        m = re.search(r'(\\d{2}\\.\\d{2}\\.\\d{4})', title_text)\n",
    "        try:\n",
    "            date_str = m.group(1)  # type: ignore\n",
    "        except:  # noqa: E722\n",
    "            print(f'Could not match date format for {title_text}')\n",
    "            continue\n",
    "        date_obj = parse_date(date_str)\n",
    "\n",
    "        if since > date_obj:\n",
    "            stop = True\n",
    "            break\n",
    "\n",
    "        results.append({'date': date_str, 'date_obj': date_obj, 'href': href})\n",
    "\n",
    "    page += 1\n",
    "\n",
    "results.sort(key=lambda x: x['date_obj'], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1344202",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import timedelta\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "\n",
    "def alternating_pairs(n):\n",
    "    for i in range(1, n + 1):\n",
    "        yield -i\n",
    "        yield i\n",
    "\n",
    "\n",
    "one_day = timedelta(1)\n",
    "\n",
    "\n",
    "def stringify_date(date_obj: date) -> str:\n",
    "    return date_obj.strftime('%Y/%m/%d')\n",
    "\n",
    "\n",
    "def try_get_video_url(r):\n",
    "    id = re.search(r'\\d+', r['href']).group()  # type: ignore\n",
    "    date_str = stringify_date(r['date_obj'])\n",
    "    vid_url = f'https://vid2.stirileprotv.ro/{date_str}/{id}-2.mp4'\n",
    "    response = requests.head(vid_url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return vid_url, date_str, id\n",
    "    elif response.status_code == 404:\n",
    "        for td in alternating_pairs(2 * 365):\n",
    "            td = timedelta(td)\n",
    "            try_date = r['date_obj'] + td\n",
    "            date_str = stringify_date(try_date)\n",
    "            vid_url = f'https://vid2.stirileprotv.ro/{date_str}/{id}-2.mp4'\n",
    "            response = requests.head(vid_url)\n",
    "            if response.status_code == 200:\n",
    "                print(f'Found for {r[\"date\"]} at {date_str} actually.')\n",
    "                return vid_url, date_str, id\n",
    "            elif response.status_code == 404:\n",
    "                continue\n",
    "            else:\n",
    "                raise ValueError(f\"Something's wrong for {r['date']}\")\n",
    "        raise ValueError(f'Could not find for {r[\"date\"]}')\n",
    "    else:\n",
    "        raise ValueError(f\"Something's wrong for {r['date']}\")\n",
    "\n",
    "\n",
    "downloaded = 0\n",
    "\n",
    "root = 'scraped'\n",
    "\n",
    "for r in results:\n",
    "    vid_url, date_str, id = try_get_video_url(r)\n",
    "    Path(os.path.join(root, date_str)).mkdir(parents=True, exist_ok=True)\n",
    "    file_name = os.path.join(root, date_str, id + '-2.mp4')\n",
    "    if os.path.exists(file_name):\n",
    "        print(f'Skipping {file_name}')\n",
    "        continue\n",
    "    with requests.get(vid_url, stream=True) as r:\n",
    "        r.raise_for_status()\n",
    "        with open(file_name, 'wb') as f:\n",
    "            # Be nice to the server!\n",
    "            for chunk in r.iter_content(chunk_size=1024 * 1024):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "                    downloaded += len(chunk)\n",
    "                    if downloaded >= 1024 * 1024 * 1024:\n",
    "                        print('Downloaded 1GB')\n",
    "                        downloaded -= 1024 * 1024 * 1024\n",
    "                # Be nice to the server!\n",
    "                time.sleep(1)\n",
    "    print(f'Done with {vid_url}.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
