{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0779ee98",
   "metadata": {},
   "source": [
    "# Extract sign features once for the translator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17da0015",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "notebook_dir = os.getcwd()\n",
    "project_root = os.path.abspath(os.path.join(notebook_dir, '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcbe89c",
   "metadata": {},
   "source": [
    "## Windows generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9330768c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "W, S = 8, 2  # window, stride (frames)\n",
    "BATCH = 1\n",
    "\n",
    "\n",
    "mean = 0.5 * torch.ones(3, device=device)\n",
    "mean_cpu = 0.5 * torch.ones(3)\n",
    "std = 1.0 * torch.ones(3, device=device)\n",
    "std_cpu = 1.0 * torch.ones(3)\n",
    "\n",
    "\n",
    "def resize_larger_side(img: np.ndarray, target=256) -> np.ndarray:\n",
    "    h, w = img.shape[:2]\n",
    "    if h > w:\n",
    "        new_h = target\n",
    "        new_w = int(round(w * (target / h)))\n",
    "    else:\n",
    "        new_w = target\n",
    "        new_h = int(round(h * (target / w)))\n",
    "    return cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "\n",
    "def center_crop(img: np.ndarray, target=224) -> np.ndarray:\n",
    "    H, Wd, _ = img.shape\n",
    "    y0 = max((H - target) // 2, 0)\n",
    "    x0 = max((Wd - target) // 2, 0)\n",
    "    return img[y0 : y0 + target, x0 : x0 + target, :]\n",
    "\n",
    "\n",
    "def iter_window_batches(video_path: str):\n",
    "    \"\"\"Yield GPU batches shaped [B,3,8,224,224] by streaming frames.\"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        return\n",
    "    buf = deque(maxlen=W)  # holds [C,224,224]\n",
    "    batch, t = [], 0\n",
    "\n",
    "    while True:\n",
    "        ok, frame = cap.read()\n",
    "        if not ok:\n",
    "            break\n",
    "        t += 1\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame = frame.astype(np.float32)\n",
    "        frame = frame / 255.0\n",
    "        frame = resize_larger_side(frame)\n",
    "        frame = center_crop(frame)\n",
    "        frame_tensor = (torch.from_numpy(frame) - mean_cpu) / std_cpu\n",
    "        buf.append(frame_tensor.permute(2, 0, 1).contiguous())\n",
    "\n",
    "        if len(buf) == W:\n",
    "            start_idx = t - W\n",
    "            if (start_idx % S) == 0:  # aligned emit\n",
    "                win = torch.stack(list(buf), dim=1)  # [C,T,224,224]\n",
    "                batch.append(win)\n",
    "                if len(batch) == BATCH:\n",
    "                    x = torch.stack(batch, dim=0)  # [B,3,T,224,224]\n",
    "                    yield x\n",
    "                    batch.clear()\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    if batch:\n",
    "        x = torch.stack(batch, dim=0)\n",
    "        yield x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ca82e9",
   "metadata": {},
   "source": [
    "## Visualize one frame after preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba395cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "for i, batch in enumerate(\n",
    "    iter_window_batches(\n",
    "        '/home/radumicea/Projects/University/LinguSign/prima/scraped/1BbSAVwp5Tk.seg.mp4'\n",
    "    )\n",
    "):\n",
    "    if i == 60:\n",
    "        print(batch.shape)\n",
    "\n",
    "        window = batch[0]\n",
    "\n",
    "        frames = window.permute(1, 2, 3, 0)\n",
    "        frame = frames[0]\n",
    "\n",
    "        print(frame.min())\n",
    "        print(frame.max())\n",
    "\n",
    "        print(frame.shape)\n",
    "\n",
    "        plt.imshow(((frame * std_cpu + mean_cpu) * 255.0).numpy().astype(np.uint8))\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d188777",
   "metadata": {},
   "source": [
    "## Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c4773f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from libs.bsl1k.models import InceptionI3d\n",
    "\n",
    "\n",
    "W, S = 8, 2  # window, stride (frames)\n",
    "BATCH = 128\n",
    "\n",
    "\n",
    "i3d = InceptionI3d(\n",
    "    num_classes=5383,\n",
    "    num_in_frames=W,\n",
    ")\n",
    "\n",
    "ckpt = torch.load('../libs/bsl1k/bsl5k.pth.tar', map_location='cpu')\n",
    "state = ckpt['state_dict']\n",
    "# If checkpoint was saved with DataParallel and has 'module.' prefixes, strip them:\n",
    "if next(iter(state)).startswith('module.'):\n",
    "    state = {k.replace('module.', '', 1): v for k, v in state.items()}\n",
    "i3d.load_state_dict(state, strict=True)\n",
    "\n",
    "i3d = torch.nn.DataParallel(i3d).cuda().eval()\n",
    "i3d.requires_grad_(False)\n",
    "\n",
    "\n",
    "captured = []\n",
    "printed = False\n",
    "\n",
    "\n",
    "def hook(_m, _i, o):\n",
    "    # o: [B, 1024, T / 8, H / 32, W / 32]\n",
    "    global printed\n",
    "    if not printed:\n",
    "        print(o.shape)\n",
    "        printed = True\n",
    "    captured.append(o.detach().cpu())  # [B, 1024, 1, 7, 7]\n",
    "\n",
    "\n",
    "h = i3d.module.end_points['Mixed_5c'].register_forward_hook(hook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772e9d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextlib\n",
    "import os\n",
    "import zstandard as zstd\n",
    "\n",
    "\n",
    "def save_npy_zst(path: str, array: np.ndarray, level: int = 2) -> str:\n",
    "    if path.endswith('.npz'):\n",
    "        out_path = path[:-4] + '.npy.zst'\n",
    "    elif path.endswith('.npy.zst'):\n",
    "        out_path = path\n",
    "    else:\n",
    "        out_path = path + '.npy.zst'\n",
    "\n",
    "    cctx = zstd.ZstdCompressor(level=level)\n",
    "\n",
    "    with open(out_path, 'wb') as f:\n",
    "        with cctx.stream_writer(f) as compressor:\n",
    "            np.save(compressor, array)\n",
    "\n",
    "    return out_path\n",
    "\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "with torch.inference_mode():\n",
    "    for root, _, files in os.walk('scraped'):\n",
    "        for file in files:\n",
    "            if not file.endswith('.seg.mp4') and not file.endswith('.seg.mkv'):\n",
    "                continue\n",
    "            video_path = os.path.join(root, file)\n",
    "            out_path = video_path.replace('.mp4', '.npy.zst').replace(\n",
    "                '.mkv', '.npy.zst'\n",
    "            )\n",
    "\n",
    "            if os.path.exists(out_path):\n",
    "                print(f'[EXISTS] {video_path} -> {out_path}')\n",
    "                continue\n",
    "\n",
    "            captured.clear()\n",
    "\n",
    "            use_amp = device == 'cuda'\n",
    "            ctx = (\n",
    "                torch.autocast('cuda', dtype=torch.float16)\n",
    "                if use_amp\n",
    "                else contextlib.nullcontext()\n",
    "            )\n",
    "\n",
    "            with ctx:\n",
    "                for batch in iter_window_batches(video_path):  # expects [B,3,8,224,224]\n",
    "                    assert (\n",
    "                        batch.dim() == 5\n",
    "                        and batch.size(0) <= BATCH\n",
    "                        and batch.size(1) == 3\n",
    "                        and batch.size(2) == 8\n",
    "                        and batch.size(3) == 224\n",
    "                        and batch.size(4) == 224\n",
    "                    ), f'bad batch {tuple(batch.shape)}'\n",
    "                    _ = i3d(batch)  # hook collects [B, 1024, 1, 7, 7]\n",
    "\n",
    "            if not captured:\n",
    "                print(f'[WARN] {video_path}: no 8-frame windows. Skipping')\n",
    "                continue\n",
    "\n",
    "            feats = torch.cat(captured, dim=0).numpy()  # [N, 1024, 1, 7, 7]\n",
    "            save_npy_zst(out_path, feats)\n",
    "            print(f'[OK] {video_path}  tokens={feats.shape[0]} -> {out_path}')\n",
    "\n",
    "h.remove()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
